{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7d7aea94-07d0-41bc-88f6-fb8316da119a",
      "metadata": {
        "id": "7d7aea94-07d0-41bc-88f6-fb8316da119a"
      },
      "source": [
        "# Machine learning Work Loads Implemented for scheduling algorithms\n",
        "\n",
        "## Task 1: MNIST Classification\n",
        "## Task 2:\n",
        "## Task 3:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd61f607-b62f-4250-aee1-c830018a4661",
      "metadata": {
        "id": "cd61f607-b62f-4250-aee1-c830018a4661"
      },
      "outputs": [],
      "source": [
        "def mnist_classification_task():\n",
        "    # Load and preprocess the MNIST dataset\n",
        "    (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "    train_images = train_images.reshape((60000, 28, 28, 1))  # Reshape to 28x28x1\n",
        "    test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "    train_images = train_images.astype('float32') / 255  # Normalize pixel values\n",
        "    test_images = test_images.astype('float32') / 255\n",
        "\n",
        "    #Build a simple CNN model\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))  # 10 output classes for digits 0-9\n",
        "\n",
        "    #Training the model\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(train_images, train_labels, epochs=2, batch_size=64, validation_split=0.1)  #Change number of epochs for faster/slower training\n",
        "\n",
        "    #Evalutation\n",
        "    test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "    print(f'Task 1: MNIST Classification - Test accuracy: {test_acc * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2"
      ],
      "metadata": {
        "id": "TBtNdWdnKZEp"
      },
      "id": "TBtNdWdnKZEp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0e90c7f-6883-4ca8-bc6f-1794b8acaabe",
      "metadata": {
        "id": "e0e90c7f-6883-4ca8-bc6f-1794b8acaabe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define a simple feedforward neural network\n",
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(10, 64)  # 10 input features\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 3)  # 3 output classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Create random data for training\n",
        "def generate_data():\n",
        "    # 1000 samples, 10 features per sample\n",
        "    X = torch.rand(1000, 10)\n",
        "    # Labels for 3 classes (0, 1, or 2)\n",
        "    y = torch.randint(0, 3, (1000,))\n",
        "    return X, y\n",
        "\n",
        "# Training function\n",
        "def train_model(model, X, y, epochs=5, learning_rate=0.001):\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Move model and data to GPU if available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()  # Zero out gradients\n",
        "        outputs = model(X)     # Forward pass\n",
        "        loss = criterion(outputs, y)  # Compute loss\n",
        "        loss.backward()  # Backward pass (compute gradients)\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Main code to run the training\n",
        "def main():\n",
        "    # Generate random training data\n",
        "    X, y = generate_data()\n",
        "\n",
        "    # Create a model instance\n",
        "    model = SimpleModel()\n",
        "\n",
        "    # Train the model\n",
        "    train_model(model, X, y)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c157835d-727f-4628-83b4-4e7a372413b6",
      "metadata": {
        "id": "c157835d-727f-4628-83b4-4e7a372413b6"
      },
      "outputs": [],
      "source": [
        "def task3():\n",
        "    print(\"Code for task 2 goes here\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04a97c6e-c33a-4b8b-965a-dcca8454d1c2",
      "metadata": {
        "id": "04a97c6e-c33a-4b8b-965a-dcca8454d1c2"
      },
      "outputs": [],
      "source": [
        "def fcfs_scheduler(task_list):\n",
        "    print(\"Scheduler: Starting tasks in First-Come, First-Served order...\\n\")\n",
        "    for task in task_list:\n",
        "        task()  #However we input the task list, thats the order they will be completed.\n",
        "        print()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    #List of Machine Learning Workloads\n",
        "    tasks = [mnist_classification_task, task2, task3]\n",
        "\n",
        "    #Run the scheduler with the task list\n",
        "    fcfs_scheduler(tasks)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}